{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Capstone Project: Create a Customer Segmentation Report for Arvato Financial Services\n",
    "\n",
    "In this project, you will analyze demographics data for customers of a mail-order sales company in Germany, comparing it against demographics information for the general population. You'll use unsupervised learning techniques to perform customer segmentation, identifying the parts of the population that best describe the core customer base of the company. Then, you'll apply what you've learned on a third dataset with demographics information for targets of a marketing campaign for the company, and use a model to predict which individuals are most likely to convert into becoming customers for the company. The data that you will use has been provided by our partners at Bertelsmann Arvato Analytics, and represents a real-life data science task.\n",
    "\n",
    "If you completed the first term of this program, you will be familiar with the first part of this project, from the unsupervised learning project. The versions of those two datasets used in this project will include many more features and has not been pre-cleaned. You are also free to choose whatever approach you'd like to analyzing the data rather than follow pre-determined steps. In your work on this project, make sure that you carefully document your steps and decisions, since your main deliverable for this project will be a blog post reporting your findings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries here; add more as necessary\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# magic word for producing visualizations in notebook\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 0: Get to Know the Data\n",
    "\n",
    "There are four data files associated with this project:\n",
    "\n",
    "- `Udacity_AZDIAS_052018.csv`: Demographics data for the general population of Germany; 891 211 persons (rows) x 366 features (columns).\n",
    "- `Udacity_CUSTOMERS_052018.csv`: Demographics data for customers of a mail-order company; 191 652 persons (rows) x 369 features (columns).\n",
    "- `Udacity_MAILOUT_052018_TRAIN.csv`: Demographics data for individuals who were targets of a marketing campaign; 42 982 persons (rows) x 367 (columns).\n",
    "- `Udacity_MAILOUT_052018_TEST.csv`: Demographics data for individuals who were targets of a marketing campaign; 42 833 persons (rows) x 366 (columns).\n",
    "\n",
    "Each row of the demographics files represents a single person, but also includes information outside of individuals, including information about their household, building, and neighborhood. Use the information from the first two files to figure out how customers (\"CUSTOMERS\") are similar to or differ from the general population at large (\"AZDIAS\"), then use your analysis to make predictions on the other two files (\"MAILOUT\"), predicting which recipients are most likely to become a customer for the mail-order company.\n",
    "\n",
    "The \"CUSTOMERS\" file contains three extra columns ('CUSTOMER_GROUP', 'ONLINE_PURCHASE', and 'PRODUCT_GROUP'), which provide broad information about the customers depicted in the file. The original \"MAILOUT\" file included one additional column, \"RESPONSE\", which indicated whether or not each recipient became a customer of the company. For the \"TRAIN\" subset, this column has been retained, but in the \"TEST\" subset it has been removed; it is against that withheld column that your final predictions will be assessed in the Kaggle competition.\n",
    "\n",
    "Otherwise, all of the remaining columns are the same between the three data files. For more information about the columns depicted in the files, you can refer to two Excel spreadsheets provided in the workspace. [One of them](./DIAS Information Levels - Attributes 2017.xlsx) is a top-level list of attributes and descriptions, organized by informational category. [The other](./DIAS Attributes - Values 2017.xlsx) is a detailed mapping of data values for each feature in alphabetical order.\n",
    "\n",
    "In the below cell, we've provided some initial code to load in the first two datasets. Note for all of the `.csv` data files in this project that they're semicolon (`;`) delimited, so an additional argument in the [`read_csv()`](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.read_csv.html) call has been included to read in the data properly. Also, considering the size of the datasets, it may take some time for them to load completely.\n",
    "\n",
    "You'll notice when the data is loaded in that a warning message will immediately pop up. Before you really start digging into the modeling and analysis, you're going to need to perform some cleaning. Take some time to browse the structure of the data and look over the informational spreadsheets to understand the data values. Make some decisions on which features to keep, which features to drop, and if any revisions need to be made on data formats. It'll be a good idea to create a function with pre-processing steps, since you'll need to clean all of the datasets before you work with them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load in the data\n",
    "#azdias = pd.read_csv('Udacity_AZDIAS_052018.csv', sep=';')\n",
    "customers = pd.read_csv('Udacity_CUSTOMERS_052018.csv', sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Be sure to add in a lot more cells (both markdown and code) to document your\n",
    "# approach and findings!\n",
    "customers.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Customer Segmentation Report\n",
    "\n",
    "The main bulk of your analysis will come in this part of the project. Here, you should use unsupervised learning techniques to describe the relationship between the demographics of the company's existing customers and the general population of Germany. By the end of this part, you should be able to describe parts of the general population that are more likely to be part of the mail-order company's main customer base, and which parts of the general population are less so."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Exploration:\n",
    "    1. Observe datatypes\n",
    "    2. Find percentage of NaN values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "customers.dtypes.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "null_count = []\n",
    "for i in customers:\n",
    "    value = customers[i].isnull().sum()\n",
    "    null_count.append(value)\n",
    "\n",
    "print(\"Percentage of null values in each column:\")\n",
    "for i in range(len(null_count)-1):\n",
    "    print(\"{}: {:.2f}%\".format(customers.columns[i], (null_count[i]/customers.shape[0] * 100)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for i in customers:\n",
    "#    print(i)\n",
    "#    print(customers[i].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statistics\n",
    "import random\n",
    "def preprocessing (dataframe):\n",
    "    dataframe = dataframe.copy()\n",
    "    dataframe.drop_duplicates(keep = 'first', inplace = True)\n",
    "    dataframe.replace(-1, float('NaN'), inplace=True)\n",
    "    dataframe.replace(0, float('NaN'), inplace=True)\n",
    "    \n",
    "    \n",
    "    new_list = []\n",
    "\n",
    "    for i in range(0, dataframe.shape[1]):     \n",
    "        if (dataframe.iloc[:, i].dtypes == 'object'):\n",
    "            dataframe.iloc[:, i] = pd.Categorical(dataframe.iloc[:, i])\n",
    "            dataframe.iloc[:, i] = dataframe.iloc[:, i].cat.codes \n",
    "            dataframe.iloc[:, i] = dataframe.iloc[:, i].astype('object')\n",
    "\n",
    "            new_list.append(dataframe.columns[i])\n",
    "            \n",
    "    for i in dataframe:\n",
    "        dataframe[i] = dataframe[i].fillna(dataframe[i].median())\n",
    "    \n",
    "\n",
    "    customers.drop(['LNR'], axis=1, inplace=True)\n",
    "    \n",
    "    return dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_customers = preprocessing(customers)\n",
    "cleaned_customers.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping specific columns with greater than 60% NaN values\n",
    "cleaned_customers.drop(['ALTER_KIND1', 'ALTER_KIND2', 'ALTER_KIND3', 'ALTER_KIND4'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Processing Confirmation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "null_count = []\n",
    "for i in cleaned_customers:\n",
    "    value = cleaned_customers[i].isnull().sum()\n",
    "    null_count.append(value)\n",
    "\n",
    "print(\"Percentage of null values in each column:\")\n",
    "for i in range(len(null_count)-1):\n",
    "    print(\"{}: {:.2f}%\".format(cleaned_customers.columns[i], (null_count[i]/cleaned_customers.shape[0] * 100)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_population = preprocessing(azdias)\n",
    "cleaned_population.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#    The preferred method for imputation is KNN Imputation.\n",
    "#    However, due to the large dataset, it is computationally expensive. \n",
    "#    The choice was made not to include KNN imputation, and opt for \n",
    "#    imputation using median values. \n",
    "#    \n",
    "#    Below is the code that would've been used if the dataset weren't too\n",
    "#    large. \n",
    "\n",
    "#from sklearn.impute import KNNImputer # Importing K Nearest Neighbors Algorithm\n",
    "# K Nearest Neighbours algorithm is used to replace values with its nearest neighbours - or most similar row data\n",
    "#df_final = pd.DataFrame(KNNImputer(n_neighbors=5, weights='uniform', metric='nan_euclidean').fit(cleaned_customers).transform(cleaned_customers), columns = cleaned_customers.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for i in cleaned_customers:\n",
    "#    print(cleaned_customers[i].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PCA "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Customers PCA and Kmeans clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components=20)\n",
    "X_df = pca.fit(cleaned_customers).transform(cleaned_customers)\n",
    "pca.explained_variance_ratio_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "PC = range(1, pca.n_components_+1)\n",
    "plt.bar(PC, pca.explained_variance_ratio_, color='gold')\n",
    "plt.xlabel('Principal Components')\n",
    "plt.ylabel('Variance %')\n",
    "plt.xticks(PC)\n",
    "\n",
    "# Putting components in a dataframe for later\n",
    "PCA_components = pd.DataFrame(X_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=2)\n",
    "pca_customers = pca.fit(cleaned_customers).transform(cleaned_customers)\n",
    "pca.explained_variance_ratio_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans # Importing K-Means algorithm \n",
    "from sklearn.impute import KNNImputer # Importing K Nearest Neighbors Algorithm\n",
    "from sklearn.linear_model import LinearRegression # Importing Linear Regression model \n",
    "from sklearn.metrics import mean_squared_error # Evaluation metric \n",
    "from sklearn.model_selection import train_test_split # Preprocessing for training and testing data splits \n",
    "\n",
    "from yellowbrick.cluster import KElbowVisualizer # Importing Elbow Method Library\n",
    "\n",
    "model = KMeans()\n",
    "visualizer = KElbowVisualizer(model, k=(1,15)) # Loop through model to find ideal number of clusters within the data\n",
    "\n",
    "visualizer.fit(PCA_components)\n",
    "visualizer.show()\n",
    "%time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "model2 = KMeans(n_clusters = 3, init = \"k-means++\")\n",
    "y2 = model2.fit_predict(X_df)\n",
    "plt.figure(figsize=(15,15))\n",
    "label2 = model2.fit_predict(X_df)\n",
    "uniq = np.unique(label2)\n",
    "for i in uniq:\n",
    "  plt.scatter(X_df[label2 == i , 0] , X_df[label2 == i , 1] , label = i)\n",
    "plt.xlabel([])\n",
    "plt.xlabel('PC1')\n",
    "plt.ylabel('PC2')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_customers['cluster'] = model2.labels_ # Adding extra column to the location dataframe to allocate data to separate groups\n",
    "cleaned_customers.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "array = model2.cluster_centers_\n",
    "array = array.astype(int)\n",
    "array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "customers['CAMEO_DEUG_2015'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "AGER_TYP\tbest-ager typology\n",
    "ALTERSKATEGORIE_GROB - age classification through prename analysis \n",
    "ANREDE_KZ - gender\n",
    "BALLRAUM - distance to next urban centre \n",
    "CAMEO_DEUG_2015 - class\n",
    "D19_BANKEN_ANZ_12 - transaction activity BANKS in the last 12 months\n",
    "D19_BANKEN_ANZ_24 -transaction activity BANKS in the last 24 months\n",
    "D19_BANKEN_DATUM - actuality of the last transaction for the segment banks TOTAL\n",
    "     \n",
    "D19_VERSAND_OFFLINE_DATUM\tactuality of the last transaction for the segment mail-order OFFLINE\n",
    "D19_VERSAND_ONLINE_DATUM\tactuality of the last transaction for the segment mail-order ONLINE\n",
    "D19_VERSAND_DATUM\tactuality of the last transaction for the segment mail-order TOTAL\n",
    "D19_VERSAND_ONLINE_QUOTE_12\tamount of online transactions within all transactions in the segment mail-order \n",
    "D19_VOLLSORTIMENT_RZ\ttransactional activity based on the product group COMPLETE MAIL-ORDER OFFERS\n",
    "D19_BANKEN_ONLINE_DATUM\n",
    "D19_BANKEN_ONLINE_QUOTE_12\n",
    "FINANZ_MINIMALIST\tfinancial typology: low financial interest\n",
    "FINANZ_SPARER\tfinancial typology: money saver\n",
    "FINANZ_VORSORGER\tfinancial typology: be prepared\n",
    "FINANZ_ANLEGER\tfinancial typology: investor\n",
    "FINANZ_UNAUFFAELLIGER\tfinancial typology: unremarkable\n",
    "FINANZ_HAUSBAUER\tfinancial typology: main focus is the own house\n",
    "FINANZTYP\tbest descirbing financial type for the peron\n",
    "GEBURTSJAHR\tyear of birth\n",
    "GFK_URLAUBERTYP\tvacation habits\n",
    "GREEN_AVANTGARDE\tthe environmental sustainability is the dominating movement in the youth of these consumers\n",
    "HEALTH_TYP\thealth typology\n",
    "LP_LEBENSPHASE_FEIN\tlifestage fine\n",
    "LP_LEBENSPHASE_GROB\tlifestage rough\n",
    "LP_FAMILIE_FEIN\tfamily type fine\n",
    "LP_FAMILIE_GROB\tfamily type rough\n",
    "LP_STATUS_FEIN\tsocial status fine \n",
    "LP_STATUS_GROB\tsocial status rough\n",
    "NATIONALITAET_KZ\tnationaltity\n",
    "PRAEGENDE_JUGENDJAHRE\tdominating movement in the person's youth (avantgarde or mainstream)\n",
    "RETOURTYP_BK_S\treturn type\n",
    "SEMIO_SOZ\taffinity indicating in what way the person is social minded\n",
    "SEMIO_FAM\taffinity indicating in what way the person is familiar minded\n",
    "SEMIO_REL\taffinity indicating in what way the person is religious\n",
    "SEMIO_MAT\taffinity indicating in what way the person is material minded\n",
    "SEMIO_VERT\taffinity indicating in what way the person is dreamily\n",
    "SEMIO_LUST\taffinity indicating in what way the person is sensual minded\n",
    "SEMIO_ERL\taffinity indicating in what way the person is eventful orientated\n",
    "SEMIO_KULT\taffinity indicating in what way the person is cultural minded\n",
    "SEMIO_RAT\taffinity indicating in what way the person is of a rational mind\n",
    "SEMIO_KRIT\taffinity indicating in what way the person is critical minded\n",
    "SEMIO_DOM\taffinity indicating in what way the person is dominant minded\n",
    "SEMIO_KAEM\taffinity indicating in what way the person is of a fightfull attitude\n",
    "SEMIO_PFLICHT\taffinity indicating in what way the person is dutyfull traditional minded\n",
    "SEMIO_TRADV\taffinity indicating in what way the person is traditional minded\n",
    "SHOPPER_TYP\tshopping typology\n",
    "SOHO_FLAG\tsmall office/home office flag\n",
    "TITEL_KZ\tflag whether this person holds an academic title\n",
    "VERS_TYP\tinsurance typology \n",
    "ZABEOTYP\ttypification of energy consumers\n",
    "GEBAEUDETYP_RASTER\tindustrial areas\n",
    "KKK\tpurchasing power\n",
    "MOBI_REGIO\tmoving patterns\n",
    "ONLINE_AFFINITAET\tonline affinity\n",
    "REGIOTYP\tAZ neighbourhood typology"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe_cluster_0 = cleaned_customers[cleaned_customers['cluster'] == 0]\n",
    "dataframe_cluster_1 = cleaned_customers[cleaned_customers['cluster'] == 1]\n",
    "dataframe_cluster_2 = cleaned_customers[cleaned_customers['cluster'] == 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "#define data\n",
    "data = [len(dataframe_cluster_0), len(dataframe_cluster_1), len(dataframe_cluster_2)]\n",
    "labels = ['Cluster 1', 'Cluster 2', 'Cluster 3']\n",
    "\n",
    "#define Seaborn color palette to use\n",
    "colors = sns.color_palette('pastel')[0:5]\n",
    "\n",
    "#create pie chart\n",
    "plt.pie(data, labels = labels, colors = colors, autopct='%.0f%%')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rfc_df = cleaned_customers.copy()\n",
    "rfc_y = rfc_df.pop('cluster')\n",
    "rfc_X = rfc_df[:]\n",
    "rfc_X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc_y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "rfc_X_train, rfc_X_test, rfc_y_train, rfc_y_test = train_test_split(rfc_X, rfc_y)\n",
    "from sklearn.svm import SVC\n",
    "rfc = RandomForestClassifier()\n",
    "rfc.fit(rfc_X_train, rfc_y_train)\n",
    "rfc_pred = rfc.predict(rfc_X_test)\n",
    "# Add pipeline for grid search to optimize model\n",
    "from sklearn.metrics import accuracy_score\n",
    "print (\"Accuracy : {:.2f}%\".format(accuracy_score(rfc_y_test, rfc_pred)*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc_array = rfc.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df = pd.DataFrame(array.reshape(1, 368), columns=X.columns)\n",
    "rfc_importances = []\n",
    "count = 0\n",
    "for i in rfc_array:\n",
    "    rfc_importances.append([i, rfc_X.columns[count]])\n",
    "    count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc_importances.sort(reverse=True)\n",
    "rfc_labels = []\n",
    "rfc_values = []\n",
    "for i in rfc_importances[0:20]:\n",
    "    rfc_labels.append(i[1])\n",
    "    rfc_values.append(i[0])\n",
    "rfc_importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.barplot(rfc_labels, rfc_values)\n",
    "plt.xticks(rotation=90)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "figure, axes = plt.subplots(1, 3, sharex=True, figsize=(15,5))\n",
    "figure.suptitle('Distribution of Gender in Each Cluster', fontsize=20)\n",
    "\n",
    "sns.distplot(dataframe_cluster_0['ANREDE_KZ'],  ax=axes[0], color ='red', bins = 2, kde = False)\n",
    "\n",
    "sns.distplot(dataframe_cluster_1['ANREDE_KZ'],  ax=axes[1], color ='red', bins = 2, kde = False)\n",
    "\n",
    "sns.distplot(dataframe_cluster_2['ANREDE_KZ'],  ax=axes[2], color ='red', bins = 2, kde = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Observations:\n",
    "- The majority of customers are male. \n",
    "- The first cluster has a more even distribution of males to females as compared to the other two clusters. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figure, axes = plt.subplots(1, 3, sharex=True, figsize=(15,5))\n",
    "figure.suptitle('Distribution of Age in Each Cluster', fontsize=20)\n",
    "\n",
    "sns.distplot(dataframe_cluster_0['ALTERSKATEGORIE_GROB'],  ax=axes[0], color ='red', bins = 10, kde = False)\n",
    "\n",
    "sns.distplot(dataframe_cluster_1['ALTERSKATEGORIE_GROB'],  ax=axes[1], color ='red', bins = 10, kde = False)\n",
    "\n",
    "sns.distplot(dataframe_cluster_2['ALTERSKATEGORIE_GROB'],  ax=axes[2], color ='red', bins = 10, kde = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Oberservations:\n",
    "- The first cluster has a younger population with individuals falling into the category of less than 30 years of age, and between the ages of 30 and 45. \n",
    "- The second cluster tends to have a larger population of middle aged individuals ranging from 46 - 60 years of age. \n",
    "- The third cluster has the largest percentage of individuals who are over the age of 60 years of age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figure, axes = plt.subplots(1, 3, sharex=True, figsize=(15, 5))\n",
    "figure.suptitle('Transaction level of Each Cluster', fontsize=20)\n",
    "\n",
    "sns.distplot(dataframe_cluster_0['D19_VERSAND_ONLINE_DATUM'],  ax=axes[0], color ='red', bins = 20, kde = False)\n",
    "\n",
    "sns.distplot(dataframe_cluster_1['D19_VERSAND_ONLINE_DATUM'],  ax=axes[1], color ='red', bins = 20, kde = False)\n",
    "\n",
    "sns.distplot(dataframe_cluster_2['D19_VERSAND_ONLINE_DATUM'],  ax=axes[2], color ='red', bins = 20, kde = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figure, axes = plt.subplots(1, 3, sharex=True, figsize=(15, 5))\n",
    "figure.suptitle('Distance from City Center of Each Cluster', fontsize=20)\n",
    "\n",
    "sns.distplot(dataframe_cluster_0['BALLRAUM'],  ax=axes[0], color ='red', bins = 20, kde = False)\n",
    "\n",
    "sns.distplot(dataframe_cluster_1['BALLRAUM'],  ax=axes[1], color ='red', bins = 20, kde = False)\n",
    "\n",
    "sns.distplot(dataframe_cluster_2['BALLRAUM'],  ax=axes[2], color ='red', bins = 20, kde = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figure, axes = plt.subplots(1, 3, sharex=True, figsize=(15, 5))\n",
    "figure.suptitle('Online Transaction Activity of Each Cluster', fontsize=20)\n",
    "\n",
    "sns.distplot(dataframe_cluster_0['D19_VERSAND_ONLINE_DATUM'],  ax=axes[0], color ='red', bins = 20, kde = False)\n",
    "\n",
    "sns.distplot(dataframe_cluster_1['D19_VERSAND_ONLINE_DATUM'],  ax=axes[1], color ='red', bins = 20, kde = False)\n",
    "\n",
    "sns.distplot(dataframe_cluster_2['D19_VERSAND_ONLINE_DATUM'],  ax=axes[2], color ='red', bins = 20, kde = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figure, axes = plt.subplots(1, 3, sharex=True, figsize=(15, 5))\n",
    "figure.suptitle('Online Transactions within all Transactions in the Segment Mail-Order of Each Cluster', fontsize=20)\n",
    "\n",
    "sns.distplot(dataframe_cluster_0['D19_VERSAND_ONLINE_QUOTE_12'],  ax=axes[0], color ='red', bins = 20, kde = False)\n",
    "\n",
    "sns.distplot(dataframe_cluster_1['D19_VERSAND_ONLINE_QUOTE_12'],  ax=axes[1], color ='red', bins = 20, kde = False)\n",
    "\n",
    "sns.distplot(dataframe_cluster_2['D19_VERSAND_ONLINE_QUOTE_12'],  ax=axes[2], color ='red', bins = 20, kde = False)\n",
    "\n",
    "#sns.distplot(dataframe_cluster_3['D19_VERSAND_ONLINE_QUOTE_12'],  ax=axes[1, 1], color ='red', bins = 20, kde = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figure, axes = plt.subplots(1, 3, sharex=True, figsize=(15, 5))\n",
    "figure.suptitle('Rough Social Status of Each Cluster', fontsize=20)\n",
    "\n",
    "sns.distplot(dataframe_cluster_0['LP_STATUS_GROB'],  ax=axes[0], color ='red', bins = 3, kde = False)\n",
    "\n",
    "sns.distplot(dataframe_cluster_1['LP_STATUS_GROB'],  ax=axes[1], color ='red', bins = 3, kde = False)\n",
    "\n",
    "sns.distplot(dataframe_cluster_2['LP_STATUS_GROB'],  ax=axes[2], color ='red', bins = 3, kde = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figure, axes = plt.subplots(1, 3, sharex=True, figsize=(15, 5))\n",
    "figure.suptitle('Good Social Status of Each Cluster', fontsize=20)\n",
    "\n",
    "sns.distplot(dataframe_cluster_0['LP_STATUS_FEIN'],  ax=axes[0], color ='red', bins = 3, kde = False)\n",
    "\n",
    "sns.distplot(dataframe_cluster_1['LP_STATUS_FEIN'],  ax=axes[1], color ='red', bins = 3, kde = False)\n",
    "\n",
    "sns.distplot(dataframe_cluster_2['LP_STATUS_FEIN'],  ax=axes[2], color ='red', bins = 3, kde = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figure, axes = plt.subplots(1, 3, sharex=True, figsize=(15,5))\n",
    "figure.suptitle('Class of Each Cluster', fontsize=20)\n",
    "\n",
    "sns.distplot(dataframe_cluster_0['CAMEO_DEUG_2015'],  ax=axes[0], color ='red', bins = 10, kde = False)\n",
    "\n",
    "sns.distplot(dataframe_cluster_1['CAMEO_DEUG_2015'],  ax=axes[1], color ='red', bins = 10, kde = False)\n",
    "\n",
    "sns.distplot(dataframe_cluster_2['CAMEO_DEUG_2015'],  ax=axes[2], color ='red', bins = 10, kde = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figure, axes = plt.subplots(1, 3, sharex=True, figsize=(15,5))\n",
    "figure.suptitle('Number of Cars in Postal Code Area of Each Cluster', fontsize=20)\n",
    "\n",
    "sns.distplot(dataframe_cluster_0['KBA13_ANZAHL_PKW'],  ax=axes[0], color ='red', bins = 10, kde = False)\n",
    "\n",
    "sns.distplot(dataframe_cluster_1['KBA13_ANZAHL_PKW'],  ax=axes[1], color ='red', bins = 10, kde = False)\n",
    "\n",
    "sns.distplot(dataframe_cluster_2['KBA13_ANZAHL_PKW'],  ax=axes[2], color ='red', bins = 10, kde = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figure, axes = plt.subplots(1, 3, sharex=True, figsize=(15,5))\n",
    "figure.suptitle('Number of Households in Postal Code Area of Each Cluster', fontsize=20)\n",
    "\n",
    "sns.distplot(dataframe_cluster_0['PLZ8_HHZ'],  ax=axes[0], color ='red', bins = 10, kde = False)\n",
    "\n",
    "sns.distplot(dataframe_cluster_1['PLZ8_HHZ'],  ax=axes[1], color ='red', bins = 10, kde = False)\n",
    "\n",
    "sns.distplot(dataframe_cluster_2['PLZ8_HHZ'],  ax=axes[2], color ='red', bins = 10, kde = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figure, axes = plt.subplots(1, 3, sharex=True, figsize=(15,5))\n",
    "figure.suptitle('Development of Most Recent Car Segment in Postal Code Area of Each Cluster', fontsize=20)\n",
    "\n",
    "sns.distplot(dataframe_cluster_0['KBA05_MODTEMP'],  ax=axes[0], color ='red', bins = 10, kde = False)\n",
    "\n",
    "sns.distplot(dataframe_cluster_1['KBA05_MODTEMP'],  ax=axes[1], color ='red', bins = 10, kde = False)\n",
    "\n",
    "sns.distplot(dataframe_cluster_2['KBA05_MODTEMP'],  ax=axes[2], color ='red', bins = 10, kde = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figure, axes = plt.subplots(1, 3, sharex=True, figsize=(15,5))\n",
    "figure.suptitle('Development of Most Recent Car Manufacturer in Postal Code Area of Each Cluster', fontsize=20)\n",
    "\n",
    "sns.distplot(dataframe_cluster_0['KBA05_HERSTTEMP'],  ax=axes[0], color ='red', bins = 10, kde = False)\n",
    "\n",
    "sns.distplot(dataframe_cluster_1['KBA05_HERSTTEMP'],  ax=axes[1], color ='red', bins = 10, kde = False)\n",
    "\n",
    "sns.distplot(dataframe_cluster_2['KBA05_HERSTTEMP'],  ax=axes[2], color ='red', bins = 10, kde = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figure, axes = plt.subplots(1, 3, sharex=True, figsize=(15, 5))\n",
    "figure.suptitle('Number of Buildings in Postal Code Area of Each Cluster', fontsize=20)\n",
    "\n",
    "sns.distplot(dataframe_cluster_0['PLZ8_GBZ'],  ax=axes[0], color ='red', bins = 10, kde = False)\n",
    "\n",
    "sns.distplot(dataframe_cluster_1['PLZ8_GBZ'],  ax=axes[1], color ='red', bins = 10, kde = False)\n",
    "\n",
    "sns.distplot(dataframe_cluster_2['PLZ8_GBZ'],  ax=axes[2], color ='red', bins = 10, kde = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figure, axes = plt.subplots(1, 3, sharex=True, figsize=(15, 5))\n",
    "figure.suptitle('Share of Cars Per Household of Each Cluster', fontsize=20)\n",
    "\n",
    "sns.distplot(dataframe_cluster_0['KBA13_AUTOQUOTE'],  ax=axes[0], color ='red', bins = 5, kde = False)\n",
    "\n",
    "sns.distplot(dataframe_cluster_1['KBA13_AUTOQUOTE'],  ax=axes[1], color ='red', bins = 5, kde = False)\n",
    "\n",
    "sns.distplot(dataframe_cluster_2['KBA13_AUTOQUOTE'],  ax=axes[2], color ='red', bins = 5, kde = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figure, axes = plt.subplots(1, 3, sharex=True, figsize=(15, 5))\n",
    "figure.suptitle('Residential Area of Each Cluster', fontsize=20)\n",
    "\n",
    "sns.distplot(dataframe_cluster_0['WOHNLAGE'],  ax=axes[0], color ='red', bins = 8, kde = False)\n",
    "\n",
    "sns.distplot(dataframe_cluster_1['WOHNLAGE'],  ax=axes[1], color ='red', bins = 8, kde = False)\n",
    "\n",
    "sns.distplot(dataframe_cluster_2['WOHNLAGE'],  ax=axes[2], color ='red', bins = 8, kde = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figure, axes = plt.subplots(1, 3, sharex=True, figsize=(15, 5))\n",
    "figure.suptitle('Unemployment of Each Cluster', fontsize=20)\n",
    "\n",
    "sns.distplot(dataframe_cluster_0['RELAT_AB'],  ax=axes[0], color ='red', bins = 6, kde = False)\n",
    "\n",
    "sns.distplot(dataframe_cluster_1['RELAT_AB'],  ax=axes[1], color ='red', bins = 6, kde = False)\n",
    "\n",
    "sns.distplot(dataframe_cluster_2['RELAT_AB'],  ax=axes[2], color ='red', bins = 6, kde = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figure, axes = plt.subplots(1, 3, sharex=True, figsize=(15, 5))\n",
    "figure.suptitle('Unemployment of Each Cluster', fontsize=20)\n",
    "\n",
    "sns.distplot(dataframe_cluster_0['KBA13_KMH_0_140'],  ax=axes[0], color ='red', bins = 5, kde = False)\n",
    "\n",
    "sns.distplot(dataframe_cluster_1['KBA13_KMH_0_140'],  ax=axes[1], color ='red', bins = 5, kde = False)\n",
    "\n",
    "sns.distplot(dataframe_cluster_2['KBA13_KMH_0_140'],  ax=axes[2], color ='red', bins = 5, kde = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_customers = cleaned_customers.filter(['AGER_TYP', 'ALTERSKATEGORIE_GROB', 'ANREDE_KZ', 'BALLRAUM', 'D19_BANKEN_ANZ_12', 'D19_BANKEN_ANZ_24', \n",
    "                                       'D19_BANKEN_ANZ_24',\n",
    "                          'D19_BANKEN_DATUM', 'D19_VERSAND_OFFLINE_DATUM', 'D19_VERSAND_ONLINE_DATUM', 'D19_VERSAND_DATUM',\n",
    "                           'D19_VERSAND_ONLINE_QUOTE_12', 'FINANZ_MINIMALIST', 'FINANZ_SPARER', 'FINANZ_VORSORGER',\n",
    "                          'FINANZ_ANLEGER', 'FINANZ_UNAUFFAELLIGER', 'FINANZ_HAUSBAUER', 'FINANZTYP', 'GEBURTSJAHR',\n",
    "                          'GFK_URLAUBERTYP', 'GREEN_AVANTGARDE', 'HEALTH_TYP', 'LP_LEBENSPHASE_FEIN',\n",
    "                          'LP_LEBENSPHASE_GROB', 'LP_FAMILIE_FEIN', 'LP_FAMILIE_GROB', 'LP_STATUS_FEIN',\n",
    "                          'LP_STATUS_GROB', 'NATIONALITAET_KZ', 'PRAEGENDE_JUGENDJAHRE', 'RETOURTYP_BK_S',\n",
    "                          'SEMIO_SOZ', 'SEMIO_FAM', 'SEMIO_REL', 'SEMIO_MAT', 'SEMIO_VERT', 'SEMIO_LUST',\n",
    "                           'SEMIO_ERL', 'SEMIO_KULT', 'SEMIO_RAT', 'SEMIO_KRIT', 'SEMIO_DOM', 'SEMIO_KAEM',\n",
    "                          'SEMIO_PFLICHT', 'SEMIO_TRADV', 'SHOPPER_TYP', 'SOHO_FLAG', 'TITEL_KZ', \n",
    "                           'VERS_TYP', 'ZABEOTYP', 'GEBAEUDETYP_RASTER', 'KKK', 'MOBI_REGIO',\n",
    "                           'ONLINE_AFFINITAET', 'REGIOTYP'])\n",
    "\n",
    "for i in filtered_customers:\n",
    "        filtered_customers[i] = filtered_customers[i].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sns.set_theme(style=\"white\")\n",
    "\n",
    "# Obtaining correlation matrix\n",
    "#corr_df = filtered_customers.copy() #.drop(['cluster'], axis=1)\n",
    "corr = filtered_customers.corr()\n",
    "\n",
    "# Matplotlib graph setup \n",
    "f, ax = plt.subplots(figsize=(20, 20))\n",
    "\n",
    "# Generating Seaplot colormap\n",
    "cmap = sns.diverging_palette(230, 20, as_cmap=True)\n",
    "\n",
    "sns.heatmap(corr, cmap=cmap, vmax=1, center=0,\n",
    "            square=True, linewidths=1, cbar_kws={\"shrink\": 1}, fmt=\".2f\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Supervised Learning Model\n",
    "\n",
    "Now that you've found which parts of the population are more likely to be customers of the mail-order company, it's time to build a prediction model. Each of the rows in the \"MAILOUT\" data files represents an individual that was targeted for a mailout campaign. Ideally, we should be able to use the demographic information from each individual to decide whether or not it will be worth it to include that person in the campaign.\n",
    "\n",
    "The \"MAILOUT\" data has been split into two approximately equal parts, each with almost 43 000 data rows. In this part, you can verify your model with the \"TRAIN\" partition, which includes a column, \"RESPONSE\", that states whether or not a person became a customer of the company following the campaign. In the next part, you'll need to create predictions on the \"TEST\" partition, where the \"RESPONSE\" column has been withheld."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_csv = pd.read_csv('Udacity_MAILOUT_052018_TRAIN.csv', sep=';')\n",
    "train_csv.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = train_csv.pop('RESPONSE')\n",
    "X = train_csv[:]\n",
    "X = preprocessing(X)\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y.count())\n",
    "print(y.nunique())\n",
    "print(y.head())\n",
    "\n",
    "def response_counter(response_array):\n",
    "    number_of_yes = 0 \n",
    "    number_of_no = 0\n",
    "    for i in response_array:\n",
    "        if i == 1:\n",
    "            number_of_yes += 1\n",
    "        else:\n",
    "            number_of_no += 1\n",
    "    return number_of_yes, number_of_no\n",
    "\n",
    "number_of_yes, number_of_no = response_counter(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components=20)\n",
    "X_df = pca.fit(X).transform(X)\n",
    "pca.explained_variance_ratio_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "#std_wine = StandardScaler().fit_transform(filtered_customers)\n",
    "\n",
    "#pca = PCA(n_components=20)\n",
    "#principalComponents = pca.fit_transform(filtered_customers)\n",
    "\n",
    "PC = range(1, pca.n_components_+1)\n",
    "plt.bar(PC, pca.explained_variance_ratio_, color='gold')\n",
    "plt.xlabel('Principal Components')\n",
    "plt.ylabel('Variance %')\n",
    "plt.xticks(PC)\n",
    "\n",
    "# Putting components in a dataframe for later\n",
    "PCA_components = pd.DataFrame(X_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components=2)\n",
    "X_df = pca.fit(X).transform(X)\n",
    "pca.explained_variance_ratio_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_df, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response_counter(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response_counter(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "clf = SVC(gamma='auto', kernel='sigmoid')\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add pipeline for grid search to optimize model\n",
    "from sklearn.metrics import accuracy_score\n",
    "y_pred = clf.predict(X_test)\n",
    "print (\"Accuracy : {:.2f}%\".format(accuracy_score(y_test, y_pred)*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score\n",
    "precision_score(y_test, y_pred, average=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import recall_score\n",
    "recall_score(y_test, y_pred, average=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response_counter(y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicting Purchasing Patterns on Customers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_dataframe_cluster_1 = dataframe_cluster_0.copy()\n",
    "predicted_dataframe_cluster_2 = dataframe_cluster_1.copy()\n",
    "predicted_dataframe_cluster_3 = dataframe_cluster_2.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prediction_function(dataframe):\n",
    "    dataframe.drop(['CUSTOMER_GROUP', 'ONLINE_PURCHASE', 'PRODUCT_GROUP', 'cluster'], axis=1, inplace=True)\n",
    "    pca = PCA(n_components=2)\n",
    "    X_component = pca.fit(dataframe).transform(dataframe)\n",
    "    y_pred = clf.predict(X_component)\n",
    "    dataframe['prediction'] = y_pred\n",
    "    number_of_yes, number_of_no = response_counter(dataframe['prediction'])\n",
    "    print(\"Percentage of Responses: {:.2f}%\".format(number_of_yes/(number_of_yes + number_of_no)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_function(predicted_dataframe_cluster_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_function(predicted_dataframe_cluster_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_function(predicted_dataframe_cluster_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_csv = pd.read_csv('Udacity_MAILOUT_052018_TEST.csv', sep=';')\n",
    "test_csv.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = test_csv[:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = clf.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_csv['cluster'] = model2.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_csv.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Total Consumer Base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_azdias = preprocessing(azdias)\n",
    "cleaned_azdias.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "azdias_df = pca.fit(cleaned_azdias).transform(cleaned_azdias)\n",
    "pca.explained_variance_ratio_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label2 = model2.fit_predict(azdias_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_azdias['cluster'] = model2.labels_\n",
    "cleaned_azdias.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_azdias['prediction'] = y_pred\n",
    "number_of_yes, number_of_no = response_counter(cleaned_azdias['prediction'])\n",
    "print(\"Percentage of Responses: {:.2f}%\".format(number_of_yes/(number_of_yes + number_of_no)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion: \n",
    "\n",
    "From the data we can conclude that the first cluster has the highest chance of purchasing the mail-order product. These tend to be younger individuals, from area codes where the number of cars is smaller and the number of buildings in the postal codes are fewer than the two other groups of individuals. \n",
    "\n",
    "This may hint at the idea that the most likely purchasers of the mail-order product are younger individuals below the ages of 46 and that are living in areas experiencing economic growth as the number of new car manufacturers and buildings are increasing. The data also suggests that this group of people make up the majority of its customers - which is a positive sign. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
